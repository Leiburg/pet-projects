{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"# %% [code] {\"_kg_hide-input\":false}\n# %% [code]\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, balanced_accuracy_score, cohen_kappa_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime as dt\nimport pickle\nimport zipfile\nimport PIL\nimport shutil\nfrom IPython.display import FileLink\nfrom time import time\nfrom IPython.display import display\nimport numpy as np # linear algebra\nimport IPython.display as ipd\nnp.warnings.filterwarnings('ignore')\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.layers import BatchNormalization\n\nimport os\n\nglobal last_pred\n\ndef clean_HDD_for_RUN_and_SAVE (d_PATH_to_WORKDIR,\n                                d_list_dir, \n                                d_list_file, \n                                d_list_masks):\n    print('Очистка HDD kaggle перед Run and Save:')\n    if (d_list_dir != []) and (d_list_dir != ''):\n        print('Удаление папок из списка:')\n        for i, d_path_dir in enumerate(d_list_dir):\n            \n            if os.path.exists(d_path_dir):\n                print(f'{i+1}. Ссылка на ({d_path_dir}) существует.', end='')\n                if os.path.isdir(d_path_dir):\n                    shutil.rmtree(d_path_dir)\n                    print(f'..... Папка удалена.)')\n                else:\n                    print(f'Это не папка.  .........   АХТУНГ!АХТУНГ!АХТУНГ!')\n            else:\n                print(f'{i+1}. Ссылка на папку ({d_path_dir}) НЕ существует.  .........   АХТУНГ!АХТУНГ!АХТУНГ!')\n        print('===')\n    if (d_list_file != []) and (d_list_file != ''):\n        print('Удаление файлов из списка:')\n        for i, d_file in enumerate(d_list_file):\n            \n            d_path_file = d_PATH_to_WORKDIR+d_file\n            \n            if os.path.exists(d_path_file):\n                print(f'{i+1}. Ссылка на ({d_file}) существует.', end='')\n                if os.path.isfile(d_path_file):\n                    os.remove(d_path_file)\n                    print('.... Файл удален.)')\n                else:\n                    print(f'Это не файл.  .........   АХТУНГ!АХТУНГ!АХТУНГ!')\n\n            else:\n                print(f'{i+1}. Ссылка на файл ({d_file}) НЕ существует.  .........   АХТУНГ!АХТУНГ!АХТУНГ!')\n        print('===')\n    if (d_list_masks != []) and (d_list_masks != ''):\n        print('Удаление файлов по маске из списка:')\n        d_list_from_dir = os.listdir(d_PATH_to_WORKDIR)\n        for i, d_mask in enumerate(d_list_masks):    \n            d_sum = 0\n            for item in d_list_from_dir:\n                if d_mask in item:\n                    d_path_item = d_PATH_to_WORKDIR+item\n                    os.remove(d_path_item)\n                    print(f'{i+1}. Файл ({item}) удален.)')\n                    d_sum += 1\n        if d_sum == 0:\n            print(f'Файлов по маскам из списка не найдено')\n        else:\n            print(f'Всего удалено:= {d_sum} файлов')\n        print('===')\n        return\n\ndef plot_res_dif_exp_in_one(\n        d_list_of_num_exp,\n        d_list_title,\n        d_df_results,\n        d_sdvig):\n    \n    temp_df = d_df_results[d_df_results['NUM_EXP'].isin(d_list_of_num_exp)]\n    \n    len_exp = len(d_list_of_num_exp)\n    d_str_title = ''\n    for i in range(len_exp):\n        d_str_title += str(d_list_of_num_exp[i])+', '\n    d_str_title = d_str_title[:-2]\n    \n    y=np.array([[0.0 for j in range(len_exp)] for i in range(4)])\n    \n    for d_num_exp in range(len_exp):\n        temp_df2 = temp_df[temp_df['NUM_EXP']==d_list_of_num_exp[d_num_exp]]\n        \n        list1 = temp_df2['R_VAL_ACC'].values[0][1:-1].split(', ')\n        y1 = [float(i) for i in list1]\n        \n        max1 = np.max(y1)\n        \n        y[1,d_num_exp] = max1\n        \n        ind_max1 = y1.index(max1)\n        \n        list2 = temp_df2['R_ACC'].values[0][1:-1].split(', ')\n        y2 = [float(i) for i in list2]\n        y[0,d_num_exp] = y2[ind_max1]\n        \n        list3 = temp_df2['R_LOSS'].values[0][1:-1].split(', ')\n        y3 = [float(i) for i in list3]\n        y[2,d_num_exp] = y3[ind_max1]\n        \n        list4 = temp_df2['R_VAL_LOSS'].values[0][1:-1].split(', ')\n        y4 = [float(i) for i in list4]\n        y[3,d_num_exp] = y4[ind_max1]\n        \n    \n    \n    \n    \n    x = range(0,len(d_list_of_num_exp))\n    \n    min_y1 = min(np.min(y[0,:]), np.min(y[1,:]))\n    max_y1 = max(np.max(y[0,:]), np.max(y[1,:]))\n    \n    min_y2 = min(np.min(y[2,:]), np.min(y[3,:]))\n    max_y2 = max(np.max(y[2,:]), np.max(y[3,:]))\n    \n    \n    k_razlet = 2\n\n#     Plot Line1 (Left Y Axis)\n    \n    plt.style.use('seaborn-paper')\n    sns.set(font_scale=1.1)\n    color_text = plt.get_cmap('PuBu')(0.85)\n    color_line1 = plt.get_cmap('PuBu')(0.95)\n    color_line2 = plt.get_cmap('PuBu')(0.65)\n\n    fig, ax1 = plt.subplots(1,1,figsize=(12,7), dpi= 80)\n    ax1.plot(x, y[0,:], color=color_line1, lw=3, marker = 'o', ms = 10, label='acc')\n    ax1.plot(x, y[1,:], color=color_line2, ls = '--', marker = 'o', ms = 10, label='val_acc')\n    \n\n    # Plot Line2 (Right Y Axis)\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n    ax2.plot(x, y[2,:], color='tab:red', lw=3, marker = 'o', ms = 10, label='loss')\n    ax2.plot(x, y[3,:], color='lightcoral', ls = '--', marker = 'o', ms = 10, label='val_loss')\n\n    # Decorations\n    # ax1 (left Y axis)\n    ax1.set_xlabel('Номер эксперимента', fontsize=20, color = color_text)\n    ax1.tick_params(axis='x', rotation=0, labelsize=12, labelcolor=color_text)\n    ax1.set_ylabel('Точность (accuracy)', color=color_line1, fontsize=20)\n    ax1.tick_params(axis='y', rotation=0, labelcolor=color_line1)\n    ax1.minorticks_on()\n    \n    ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='grey', alpha=0.8)\n    \n    ax1.grid(which='major', linestyle='-', linewidth='0.5', color='grey')\n    ax1.set_ylim(min_y1-k_razlet*(max_y1-min_y1), max_y1*1.05)\n    \n    y_title = (max_y1*1.05 + (min_y1-k_razlet*(max_y1-min_y1)))/2*1.1\n    \n    for i_t, title in enumerate(d_list_title):\n        plt.text(i_t - i_t/len_exp*d_sdvig, y_title, title, \n             fontsize = 18, \n             color = color_text)\n        if i_t > 0:\n            proc = y[1,:][i_t]/y[1,:][i_t-1]\n            proc = round((proc-1)*100,2)\n            ax1.text(i_t - i_t/len_exp*d_sdvig*0.8, y[1,:][i_t]*0.95, f'+{proc}%', \n                 fontsize = 20, \n                 color = 'black')\n            \n            \n\n    # ax2 (right Y axis)\n    ax2.set_ylabel(\"loss-функция\", color='tab:red', fontsize=20)\n    ax2.tick_params(axis='y', labelcolor='tab:red')\n    ax2.set_xticks(np.arange(0, len(d_list_of_num_exp), 1))\n    ax2.set_xticklabels(d_list_of_num_exp, rotation=90, fontdict={'fontsize':10})\n    ax2.set_title(f'Сравнение результатов экспериментов ({d_str_title})', \n                  fontsize=22, \n                  color = color_line1)\n    ax2.set_ylim(min_y2*0, max_y2+(max_y2-min_y2)*k_razlet)\n    \n    for i_t, title in enumerate(d_list_title):\n        if i_t > 0:\n            proc2 = y[3,:][i_t]/y[3,:][i_t-1]\n            proc2 = round((1-proc2)*100,2)\n            ax2.text(i_t - i_t/len_exp*d_sdvig*0.6, y[3,:][i_t]*1.2, f'-{proc2}%', \n                 fontsize = 20, \n                 color = 'black')\n    fig.legend(bbox_to_anchor=(0.5, -0.015), loc='lower center', ncol=4)\n    fig.tight_layout()\n    plt.show()\n    return\n\ndef soun_of_end(d_rate):\n    beep = np.sin(2*np.pi*400*np.arange(10000*2)/10000)\n    display(ipd.Audio(beep, rate=d_rate, autoplay=True))\n    return\n\ndef show_result_exp(d_num_exp, d_df_results, d_dict):\n\n    def str_to_arr(d_str):\n        d_temp_list = d_str[1:-1].split(' ')\n        d_clean_temp_list = [x for x in d_temp_list if (x != '') and (x !='...')]\n        d_temp = [float(i) for i in d_clean_temp_list]\n        d_temp_arr = np.array(d_temp)\n        return d_temp_arr\n\n    def descr_after_point(d_str):\n        d_ind = d_str.index('.')\n        return d_str[d_ind+2:]\n\n    print(f'Гиперпараметры и результаты обучения нейросети по эксперименту:= {d_num_exp} (NUM_EXP)')\n    temp_df = d_df_results[d_df_results['NUM_EXP']==d_num_exp]\n\n    temp_dict = {}\n    temp_dict['----Гиперпараметры аугментации----'] = '',''\n    for col in temp_df.columns:\n        if 'AUG_' in col:\n            temp_dict[col] = temp_df[col].values[0], descr_after_point(d_dict[col])\n    \n    temp_dict['----Гиперпараметры модели----'] = '',''\n    for col in temp_df.columns:\n        if 'M_' in col and (col != 'NUM_EXP'):\n            temp_dict[col] = temp_df[col].values[0], descr_after_point(d_dict[col])\n    \n    temp_dict['----Гиперпараметры головы----'] = '',''\n    for col in temp_df.columns:\n        if ('H_' in col) and ('R_' not in col):\n            temp_dict[col] = temp_df[col].values[0], descr_after_point(d_dict[col])\n    \n    temp_dict['----Гиперпараметры компиляции----'] = '',''\n    for col in temp_df.columns:\n        if 'C_' in col:\n            temp_dict[col] = temp_df[col].values[0], descr_after_point(d_dict[col])\n\n    temp_dict['----Результаты обучения----'] = '',''\n    col = 'R_EVA_VAL_ACC'\n    temp_dict[col] = temp_df[col].values[0], descr_after_point(d_dict[col])\n    col = 'R_EPOCH_TIME'\n    temp_arr = str_to_arr(temp_df[col].values[0])\n    temp_dict[col+'_mean'] = temp_arr.mean(), 'Среднее время обучения каждой эпохи (сек.)'\n    \n    col = 'R_BATCH_TIME'\n    temp_arr = str_to_arr(temp_df[col].values[0])\n    temp_dict[col+'_mean'] = temp_arr.mean(), 'Среднее время обучения каждого batch (сек.)'\n\n    col = 'R_TRAIN_TIME'\n    temp_dict[col] = temp_df[col].values[0], d_dict[col]\n\n    temp_df2 = pd.DataFrame.from_dict(temp_dict, orient='index', columns=['Значение', 'Описание'])\n    display(temp_df2)\n    return\n\ndef new_exp_without_stop_session(d_results_of_exp):\n    last_NUM_EXP = d_results_of_exp.loc[d_results_of_exp.index.max(),'NUM_EXP']\n    d_results_of_exp.loc[d_results_of_exp.index.max()+1]=d_results_of_exp.loc[d_results_of_exp.index.max()]\n    d_results_of_exp.loc[d_results_of_exp.index.max(), 'NUM_EXP']=last_NUM_EXP+1\n    for col in d_results_of_exp.columns:\n        if 'R_' in col:\n            d_results_of_exp.loc[d_results_of_exp.index.max(), col]=''\n    d_results_of_exp.loc[d_results_of_exp.index.max(), 'TIME']=''\n    print(f'Новый эксперимент без завершения сессии инициализирован.')\n    print(f'NUM_EXP = {last_NUM_EXP+1} Значение константы изменено.')\n    return last_NUM_EXP+1\n\ndef show_image(d_path, d_subtitle, d_x, d_y, d_y_subtitle):\n    plt.style.use('seaborn-paper')\n    color_text = plt.get_cmap('PuBu')(0.95)\n\n    plt.figure(figsize=(d_x,d_y))\n    plt.subplot(1, 1, 1)\n    im = PIL.Image.open(d_path)\n    plt.imshow(im)\n    plt.suptitle(d_subtitle, y = d_y_subtitle, fontsize = 18, color = color_text)\n    plt.axis('off')\n    return\n\n\ndef load_result_last_cnn_fit(d_PATH_to_FILE_RESULT, d_PATH_to_FILE_descr):\n    temp_df = pd.read_csv(d_PATH_to_FILE_RESULT)\n    with open(d_PATH_to_FILE_descr, 'rb') as f:\n        temp_dict = pickle.load(f)\n    temp = temp_df['NUM_EXP'].to_numpy()[-1].max()\n    d_NUM_EXP = hyperp('NUM_EXP',int(temp+1),'',temp_df,temp_dict)\n    return d_NUM_EXP, temp_df, temp_dict\n\ndef plot_acc_loss_fit_model_in_one(d_num_exp, d_df_results):\n    \n    temp_df = d_df_results[d_df_results['NUM_EXP']==d_num_exp]\n    \n    d_date = temp_df['TIME'].values[0]\n    d_evol_val_acc = float(temp_df['R_EVA_VAL_ACC'].values[0])\n    \n    d_time = int(float(temp_df['R_TRAIN_TIME'].values[0][1:-1]))\n    \n    list1 = temp_df['R_ACC'].values[0][1:-1].split(', ')\n    y1 = [float(i) for i in list1]\n    list2 = temp_df['R_VAL_ACC'].values[0][1:-1].split(', ')\n    y2 = [float(i) for i in list2]\n    list3 = temp_df['R_LOSS'].values[0][1:-1].split(', ')\n    y3 = [float(i) for i in list3]\n    list4 = temp_df['R_VAL_LOSS'].values[0][1:-1].split(', ')\n    y4 = [float(i) for i in list4]\n    x = range(1,len(y1)+1)\n    \n    temp_list = y3+y4\n    min_y, max_y = min(temp_list), max(temp_list)\n    y_for_text = (min_y+max_y)*0.4\n    x_for_text = len(y1)*0.75\n\n    # Plot Line1 (Left Y Axis)\n    \n    plt.style.use('seaborn-paper')\n    sns.set(font_scale=1.1)\n    color_text = plt.get_cmap('PuBu')(0.85)\n    color_line1 = plt.get_cmap('PuBu')(0.95)\n    color_line2 = plt.get_cmap('PuBu')(0.65)\n\n#     plt.figure(figsize=(12, 7))\n    fig, ax1 = plt.subplots(1,1,figsize=(12,7), dpi= 80)\n    ax1.plot(x, y1, color=color_line1, lw=3, marker = 'o', ms = 10, label='acc')\n    ax1.plot(x, y2, color=color_line2, ls = '--', marker = 'o', ms = 10, label='val_acc')\n    \n\n    # Plot Line2 (Right Y Axis)\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n    ax2.plot(x, y3, color='tab:red', lw=3, marker = 'o', ms = 10, label='loss')\n    ax2.plot(x, y4, color='lightcoral', ls = '--', marker = 'o', ms = 10, label='val_loss')\n\n    # Decorations\n    # ax1 (left Y axis)\n    ax1.set_xlabel('epochs', fontsize=20, color = color_text)\n    ax1.tick_params(axis='x', rotation=0, labelsize=12, labelcolor=color_text)\n    ax1.set_ylabel('Точность (accuracy)', color=color_line1, fontsize=20)\n    ax1.tick_params(axis='y', rotation=0, labelcolor=color_line1)\n    ax1.minorticks_on()\n    # ax1.majorticks_on()\n    ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='grey', alpha=0.8)\n    # ax1.grid(alpha=.4)\n    ax1.grid(which='major', linestyle='-', linewidth='0.5', color='grey')\n    plt.text(x_for_text, y_for_text, f'NUM_EXP = {d_num_exp} \\n{d_date}\\nVAL_ACC:={round(d_evol_val_acc,4)}\\ntime_fit:={d_time} сек. ', \n             fontsize = 18, \n             color = color_text)\n\n    # ax2 (right Y axis)\n    ax2.set_ylabel(\"loss-функция\", color='tab:red', fontsize=20)\n    ax2.tick_params(axis='y', labelcolor='tab:red')\n    ax2.set_xticks(np.arange(1, len(y1)+1, 1))\n    ax2.set_xticklabels(x, rotation=90, fontdict={'fontsize':10})\n    ax2.set_title('Графики метрики точности и значений функции потерь по эпохам', \n                  fontsize=22, \n                  color = color_line1)\n    \n    fig.legend(bbox_to_anchor=(0.5, -0.015), loc='lower center', ncol=4)\n    fig.tight_layout()\n    plt.show()\n    return\n\n\ndef hyperp_without_print(d_name_const,\n                        d_const_value,\n                        d_const_desc,\n                        d_df,\n                        d_dict):\n    d_len = len(d_df)\n    if d_name_const not in list(d_df.columns):\n        d_df[d_name_const] = None\n        d_df[d_name_const] = d_df[d_name_const].astype('object')\n        d_df.loc[d_len-1,d_name_const] = str(d_const_value)\n        d_dict[d_name_const]= d_const_desc\n    else:\n        d_df.loc[d_len-1,d_name_const] = str(d_const_value)\n    return d_const_value\n\ndef to_zip(d_path_to_file_zip, d_list_links_files):\n    with zipfile.ZipFile(d_path_to_file_zip, 'w') as d_zip_file:\n        for link in d_list_links_files:\n            d_zip_file.write(link)\n    for link in d_list_links_files:\n        if os.path.isfile(link):\n            os.remove(link)\n        else:\n            print(f'Ошибка {link} не найден')\n        \n    size_in_MB=round(os.path.getsize(d_path_to_file_zip)/(1024*1024),2)\n    file_zip = f'r{d_path_to_file_zip}'\n    link_ = os.path.basename(d_path_to_file_zip)\n    display(f'{link_} успешно создан. {size_in_MB} Mb. Ссылка для скачивания ниже:',FileLink(link_))\n    return\n\n\ndef save_model(d_PATH_to_RESULTS,\n               d_PATH_to_BEST_MODELS,\n               d_model, \n               d_history, \n               d_time_cb, \n               d_results_of_exp, \n               d_descr_hyperp_of_exp,\n               d_zip = True):\n\n    if d_history != []:\n        R_EPOCH_TIME = hyperp_without_print('R_EPOCH_TIME', d_time_cb.epoch_time, 'Результат обучения. Время обучения каждой эпохи',d_results_of_exp,d_descr_hyperp_of_exp)\n        R_BATCH_TIME = hyperp_without_print('R_BATCH_TIME', d_time_cb.batch_time, 'Результат обучения. Время обучения каждого batch',d_results_of_exp,d_descr_hyperp_of_exp)\n        R_TRAIN_TIME = hyperp_without_print('R_TRAIN_TIME', d_time_cb.train_time, 'Результат обучения. Время обучения',d_results_of_exp,d_descr_hyperp_of_exp)\n\n    if d_time_cb != []:\n        R_LOSS = hyperp_without_print('R_LOSS', d_history.history['loss'], 'Результат обучения. Значения функции потерь по каждой эпохе по тренировочной выборке',d_results_of_exp,d_descr_hyperp_of_exp)\n        R_ACC = hyperp_without_print('R_ACC', d_history.history['accuracy'], 'Результат обучения. Значения метрики точности (accuracy) по каждой эпохе по тренировочной выборке',d_results_of_exp,d_descr_hyperp_of_exp)\n        R_VAL_LOSS = hyperp_without_print('R_VAL_LOSS', d_history.history['val_loss'], 'Результат обучения. Значения функции потерь по каждой эпохе на валидационной выборке',d_results_of_exp,d_descr_hyperp_of_exp)\n        R_VAL_ACC = hyperp_without_print('R_VAL_ACC', d_history.history['val_accuracy'], 'Результат обучения. Значения метрики точности (accuracy) по каждой эпохе на валидационной выборке',d_results_of_exp,d_descr_hyperp_of_exp)\n    \n    \n    d_NUM_EXP = d_results_of_exp['NUM_EXP'].to_numpy()[-1]\n    \n    time_now = dt.now().strftime('%Y%m%d__%H_%M')\n    TIME = hyperp_without_print('TIME', time_now, 'Результат обучения. Время эксперимента',d_results_of_exp,d_descr_hyperp_of_exp)\n    \n    model_file_name = d_PATH_to_BEST_MODELS+f'best_model_{int(d_NUM_EXP)}_{time_now}.hdf5'\n    results_data_file_name = d_PATH_to_RESULTS+f'results_{int(d_NUM_EXP)}_{time_now}.csv'\n    descr_hyperp_file_name = d_PATH_to_RESULTS+f'descr_{int(d_NUM_EXP)}_{time_now}.pkl'\n    \n    d_model.save(model_file_name)\n    d_results_of_exp.to_csv(results_data_file_name, index=False)\n    with open(descr_hyperp_file_name, 'wb') as f:\n        pickle.dump(d_descr_hyperp_of_exp, f, pickle.HIGHEST_PROTOCOL)\n    if d_zip == True:\n        name_zip_1 = d_PATH_to_RESULTS+f'zip_results_{int(d_NUM_EXP)}_{time_now}.zip'\n        name_zip_2 = d_PATH_to_RESULTS+f'zip_model_{int(d_NUM_EXP)}_{time_now}.zip'\n        list_1 = [results_data_file_name,descr_hyperp_file_name]\n        list_2 = [model_file_name]\n        to_zip(name_zip_1,list_1)\n        to_zip(name_zip_2,list_2)\n    else:\n        print(f'Лучшая модель и результаты всех тестов успешно сохранены без архивирования')\n    return results_data_file_name\n\n\ndef callbacks_assembler(d_M_CALLBACKS_TYPE, d_M_LR, d_M_LR_UPDATE, d_M_EPOCHS_DROP, d_time_cb):\n    \n    def scheduler(epoch):\n        return d_M_LR * math.pow(d_M_LR_UPDATE, math.floor((1+epoch)/d_M_EPOCHS_DROP))\n    \n    callback1 = ModelCheckpoint('best_model.hdf5',    \n                                monitor='val_accuracy', \n                                verbose=1, \n                                mode='max', \n                                save_best_only=True)\n    callback2 = EarlyStopping(monitor='val_accuracy', \n                              patience=4, \n                              restore_best_weights=True,\n                              verbose=1)\n    callback3 = LearningRateScheduler(scheduler, \n                                      verbose=1)\n    \n    mix_callbacks = []\n    if 'MC' in d_M_CALLBACKS_TYPE:\n        mix_callbacks.append(callback1)\n        \n    if 'ES' in d_M_CALLBACKS_TYPE:\n        mix_callbacks.append(callback2)\n        \n    if 'LRS' in d_M_CALLBACKS_TYPE:\n        mix_callbacks.append(callback3)\n        \n    if 'T' in d_M_CALLBACKS_TYPE:\n        mix_callbacks.append(d_time_cb)\n        \n    \n    return mix_callbacks\n\n\nclass TimingCallback(Callback):\n    def __init__(self):\n        super(TimingCallback, self).__init__()\n        self.epoch_logs=[]\n        self.batch_logs=[]\n        self.train_logs=[]\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_starttime = time()\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.epoch_logs.append(time() - self.epoch_starttime)\n\n    def on_batch_begin(self, batch, logs=None):\n        self.batch_starttime = time()\n\n    def on_batch_end(self, batch, logs=None):\n        self.batch_logs.append(time() - self.batch_starttime)\n\n    def on_train_begin(self, logs=None):\n        self.train_starttime = time()\n\n    def on_train_end(self, logs=None):\n        self.train_logs.append(time() - self.train_starttime)\n\n    @property\n    def epoch_time(self):\n        return np.array(self.epoch_logs)\n\n    @property\n    def batch_time(self):\n        return np.array(self.batch_logs)\n\n    @property\n    def train_time(self):\n        return np.array(self.train_logs)\n\n\ndef model_summary_short(d_model, d_base_model=''):\n    trainable_count = np.sum([K.count_params(w) for w in d_model.trainable_weights])\n    non_trainable_count = np.sum([K.count_params(w) for w in d_model.non_trainable_weights])\n    \n    count_l_fr_m, count_l_not_fr_m, count_l_bn_m = 0, 0, 0\n    len_d_model = len(d_model.layers)\n    count_l_m, num_first_fr_l_m = len_d_model, len_d_model\n    for i in range(len_d_model, 0, -1):\n        layer = d_model.layers[i-1]\n        if layer.trainable:\n            count_l_not_fr_m += 1\n            if not isinstance(layer, BatchNormalization):\n                num_first_fr_l_m = count_l_m\n        else:\n            count_l_fr_m += 1\n            if isinstance(layer, BatchNormalization):\n                count_l_bn_m +=1\n        count_l_m -= 1\n    \n    if d_base_model != '':\n        count_l_fr_bm, count_l_not_fr_bm, count_l_bn_bm = 0, 0, 0\n        len_d_base_model = len(d_base_model.layers)\n        count_l_bm, num_first_fr_l_bm = len_d_base_model, len_d_base_model\n        for i in range(len_d_base_model, 0, -1):\n            layer = d_base_model.layers[i-1]\n            if layer.trainable:\n                count_l_not_fr_bm += 1\n                if not isinstance(layer, BatchNormalization):\n                    num_first_fr_l_bm = count_l_bm\n            else:\n                count_l_fr_bm += 1\n                if isinstance(layer, BatchNormalization):\n                    count_l_bn_bm +=1\n            count_l_bm -= 1\n    \n    \n    print('Краткая информация о моделе:')\n    temp_dict = {}\n    temp_dict['--------Параметры модели -------'] = '', '--------Params model--------'\n    temp_dict['Всего параметров'] = '{:,}'.format(trainable_count + int(non_trainable_count)), 'Total params'\n    temp_dict['Тренируемых параметров'] = '{:,}'.format(trainable_count), 'Trainable params'\n    temp_dict['Нетренируемых параметров'] = '{:,}'.format(int(non_trainable_count)), 'Non-trainable params'\n    \n    temp_dict['--------Слои модели--------'] = '', '--------Layers model--------'\n    temp_dict['Всего слоев'] = len_d_model, 'Total layers'\n    temp_dict['Тренируемых слоев (не заморожен.)'] = count_l_not_fr_m, 'Trainable layers (no frozen)'\n    temp_dict['Нетренируемых слоев (заморожен.)'] = count_l_fr_m, 'Non-trainable layers (frozen)'\n    temp_dict['.. среди них слоев bn'] = count_l_bn_m, '.. among them layers bn'\n    \n    if num_first_fr_l_m == len_d_model:\n        d_temp = 'Отсутствует'\n    else:\n        d_temp = num_first_fr_l_m\n    \n    temp_dict['Номер первого тренируемого слоя'] = d_temp, 'Count num first trainable layer'\n    \n    if d_base_model != '':\n        temp_dict['--------Слои базовой модели--------'] = '', '--------Layers base model--------'\n        temp_dict['Всего слоев бм'] = len_d_base_model, 'Total layers'\n        temp_dict['Тренируемых слоев бм (не заморожен.)'] = count_l_not_fr_bm, 'Trainable layers (no frozen)'\n        temp_dict['Нетренируемых слоев бм (заморожен.)'] = count_l_fr_bm, 'Non-trainable layers (frozen)'\n        temp_dict['... среди них слоев bn'] = count_l_bn_bm, '.. among them layers bn'\n        \n        if num_first_fr_l_bm == len_d_base_model:\n            d_temp = 100\n        else:\n            d_temp = (num_first_fr_l_m-1)/len_d_base_model\n            d_temp = int(round(d_temp,2)*100)\n        temp_dict['% заморозки базовой модели'] = f'{d_temp} %', '% freeze base model'\n        \n        temp_dict['----Архитектура головы модели----'] = '', '----Head architecture----'\n        temp_dict['Всего слоев головы'] = len_d_model - len_d_base_model, 'Total layers'\n        temp_dict['Полносвязных слоев без выходного слоя'] = 1, 'Dense layers without output layer'\n        temp_dict['BatchNormalization'] = True, 'BatchNormalization'\n        temp_dict['Функция активации скрытого слоя'] = 'relu', 'Activation func for hidden layer'\n        temp_dict['Функция активации выходного слоя'] = 'softmax', 'Activation func for output layer'\n\n        \n\n    temp_df2 = pd.DataFrame.from_dict(temp_dict, orient='index', columns=['Значение', ''])\n    display(temp_df2)\n    return\n\n\ndef model_assembler(d_base_model, d_head):\n    '''\n    Функция производит сборку модели по технике Transfer Learning.\n    За основу берется предобученная сеть, на неё устанавливается новая \n    \"голова\" (head) из свежих слоев, которые понадобятся для решения текущей задачи.\n    '''\n    d_outputs = d_base_model.output\n    \n    for l in d_head.layers:\n        d_outputs = l(d_outputs)\n\n    return Model(inputs=d_base_model.input, \n                 outputs=d_outputs)\n\ndef train_test_datagen(d_rotation_range,\n                    d_brightness_range,\n                    d_width_shift_range,\n                    d_height_shift_range,\n                    d_horizontal_flip,\n                    d_rescale,\n                    d_validation_split):\n    train_datagen = ImageDataGenerator(rotation_range=d_rotation_range,\n                                       brightness_range=d_brightness_range,\n                                       width_shift_range=d_width_shift_range,\n                                       height_shift_range=d_height_shift_range,\n                                       horizontal_flip=d_horizontal_flip,\n                                       rescale = d_rescale,\n                                       validation_split=d_validation_split)\n\n    test_datagen = ImageDataGenerator(rescale = d_rescale)\n    return train_datagen, test_datagen\n\n\n# Обертка для генераторов данных\ndef train_valid_test_generators(\n                    d_rotation_range,\n                    d_brightness_range,\n                    d_width_shift_range,\n                    d_height_shift_range,\n                    d_horizontal_flip,\n                    d_rescale,\n                    d_validation_split,\n                    d_path_to_train,\n                    d_path_to_test,\n                    d_df_submision,\n                    d_IMG_SIZE,\n                    d_BATCH_SIZE,\n                    d_RANDOM_SEED): \n    # создаем объекты с аугментацией\n    train_datagen, test_datagen = train_test_datagen(\n                    d_rotation_range,\n                    d_brightness_range,\n                    d_width_shift_range,\n                    d_height_shift_range,\n                    d_horizontal_flip,\n                    d_rescale,\n                    d_validation_split)\n\n    # генератор для тренировочной выборки\n    train_generator = train_datagen.flow_from_directory(\n        d_path_to_train,\n        target_size=(d_IMG_SIZE, d_IMG_SIZE),\n        batch_size=d_BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True,\n        seed=d_RANDOM_SEED,\n        subset='training'\n    )\n\n    # генератор для валидационной выборки\n    validation_generator = train_datagen.flow_from_directory(\n        d_path_to_train,\n        target_size=(d_IMG_SIZE, d_IMG_SIZE),\n        batch_size=d_BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True,\n        seed=d_RANDOM_SEED,\n        subset='validation'\n    )\n\n    # генератор для тестовых данных\n    test_generator = test_datagen.flow_from_dataframe(\n        dataframe=d_df_submision,\n        directory=d_path_to_test,\n        x_col=\"Id\",\n        y_col=None,\n        target_size=(d_IMG_SIZE, d_IMG_SIZE),\n        batch_size=d_BATCH_SIZE,\n        class_mode=None,\n        shuffle=False,\n        seed=d_RANDOM_SEED\n    )\n    return train_generator, validation_generator, test_generator\n\n\ndef hyperp (d_name_const,\n            d_const_value,\n            d_const_desc,\n            d_df,\n            d_dict):\n    d_len = len(d_df)\n    if d_name_const not in list(d_df.columns):\n        d_df[d_name_const] = None\n        d_df[d_name_const] = d_df[d_name_const].astype('object')\n        if d_name_const == 'NUM_EXP':\n            d_df.loc[d_len,d_name_const] = d_const_value\n        else:\n            d_df.loc[d_len-1,d_name_const] = str(d_const_value)\n        d_dict[d_name_const]= d_const_desc\n        print(f'{d_name_const} = {d_const_value} ({d_dict[d_name_const]}). Константа инициализирована.' )\n    else:\n        if d_name_const == 'NUM_EXP':\n            d_df.loc[d_len,d_name_const] = d_const_value\n        else:\n            d_df.loc[d_len-1,d_name_const] = str(d_const_value)\n        print(f'{d_name_const} = {d_const_value} Значение константы изменено.')\n    return d_const_value\n\n\ndef images_from_dataset_with_path(d_subtitle ,\n                                    d_title ,\n                                    d_path,\n                                    d_df,\n                                    d_name_column,\n                                    d_list,\n                                    d_name_column_with_path,\n                                    d_rs,\n                                    b_title=True):\n    np.random.seed(d_rs)\n\n    plt.style.use('seaborn-paper')\n    color_text = plt.get_cmap('PuBu')(0.95)\n\n    plt.figure(figsize=(14,5))\n\n    for num, i in enumerate(d_list):\n        random_image = d_df[d_df[d_name_column]==i].sample(1)\n        random_image_path = random_image.iloc[0][d_name_column_with_path]\n        \n        im = PIL.Image.open(d_path+f'{i}/{random_image_path}')\n        plt.subplot(2,5, num+1)\n        plt.imshow(im)\n        if b_title:\n            plt.title(d_title+str(i), fontsize=14, color = color_text)\n        plt.text(im.size[0]//2-80,im.size[1]+30, im.size, fontsize=8, color = color_text)\n        plt.axis('off')\n    plt.suptitle(d_subtitle, y = 0.98, fontsize = 18, color = color_text)\n    plt.show()\n    return\n\n\ndef simple_plot_barv(d_name_title,\n                    d_name_column,\n                    d_df,\n                    d_my_font_scale,\n                    d_name_axis_x,\n                    d_name_axis_y ):\n    \"\"\"\n    \n    \"\"\"\n    list_values = list(d_df[d_name_column].unique())\n\n    temp_df = d_df[d_name_column].value_counts()\n    d_mean = temp_df.values.mean()\n\n    plt.style.use('seaborn-paper')\n    sns.set(font_scale=d_my_font_scale)\n    color_text = plt.get_cmap('PuBu')(0.95)\n    color_bar = plt.get_cmap('PuBu')(0.8)\n    _, ax = plt.subplots(figsize=(12, 5))\n\n    category_colors = plt.get_cmap('PuBu')(\n            np.linspace(0.85, 0.35, len(list_values)))\n\n    widths = temp_df.values\n    ax.bar(temp_df.index, height = widths,  width=0.7, color=category_colors)  \n    for (x, y) in zip(temp_df.index, temp_df.values):\n        ax.text(x,d_mean, str(int((y-d_mean)/d_mean*100))+'%', fontsize=12, weight = 'bold', ha='center', va='center',  color=color_text)\n    ax.set_title(d_name_title+' (критерий '+d_name_column+')', loc ='center', fontsize=12, color = category_colors[0])\n    ax.set_xlabel(d_name_axis_x, fontsize=15, color = color_text)\n    ax.set_ylabel(d_name_axis_y, fontsize=15, color = color_text)\n    \n\n    plt.show()\n    return\n\n\ndef unzip(d_path_in, d_path_out, d_list_names_zips, d_comment):\n    print('Распаковываем zip-архивы ',d_comment,':', sep='')\n    i = 1\n    max_len = 0\n    for elem in d_list_names_zips:\n        d_elem = len(elem)\n        if d_elem > max_len:\n            max_len = d_elem\n    if max_len > 0:\n        for data_zip in d_list_names_zips:\n            print(i, '. ', data_zip, '.'*(20-len(data_zip)+max_len), sep='', end='')\n            with zipfile.ZipFile(d_path_in+data_zip,\"r\") as z:\n                z.extractall(d_path_out)\n            print('. Распакован.')\n            i += 1\n        print('===')\n        print(f'Текущее состояние папки ({d_path_out}):= ', end='')\n        print(os.listdir(d_path_out))\n    else:\n        print('Распаковка прервана. Причина - Список zip-архивов пустой.')\n    return\n\ndef mkdir(d_path,d_name_dir):\n    path_dir = d_path + d_name_dir + '/'\n    if not os.path.exists(path_dir):\n        os.makedirs(path_dir)\n        print(f'Директория с именем ({d_name_dir}) успешно создана в ({d_path}).')\n        print(f'Путь к новой папке ({path_dir}) возвращен в переменную.')\n    else:\n        print('Директория с таким именем уже существует.') \n        print(f'Путь к папке ({path_dir}) возвращен в переменную.')\n    return path_dir\n\n\ndef result_EDA_feature(d_feature, d_train, d_test, d_n_cols, d_EDA_done_cols, d_old_len_train):\n    # записываем признак в список проанализированных признаков\n    d_EDA_done_cols.append(d_feature)\n    d_len_ = len(d_EDA_done_cols)\n    print(f'В результате после EDA признака:= {d_feature}, обработано признаков:= {d_len_}, осталось:= {d_n_cols-d_len_}')\n    # смотрим как ведет себя трейн\n    temp = len(d_train)\n    print('Кол-во строк в трейне:= ', temp, '. Убрали на данном шаге:= ', d_old_len_train-temp)\n    d_old_len_train = temp\n    # проверяем что мы случайно не испортили тест\n    print('Кол-во строк в тесте:= ', len(d_test))\n    return d_old_len_train, d_EDA_done_cols\n\n\ndef nunique_not_found(d_df1, d_df2, d_col):\n\n    temp_set = set()\n    temp_set2 = set()\n    temp_set = set(d_df1[d_col].unique())\n    temp_set2 = set(d_df2[d_col].unique())\n\n    print(f'в столбце:= {d_col} в трейне НЕ НАЙДЕНО:= {len(temp_set2-temp_set)} уникальных значений из теста')\n\n    return list(temp_set2-temp_set)\n\ndef check_df_before_merg(d_df1,d_df2):\n    \n    list_of_names1 = list(d_df1.columns)\n    temp_dict = {}\n    temp_dict['# уник_1'] = d_df1.nunique().values\n    temp_dict['в первой строке_1'] =d_df1.loc[0].values\n    temp_dict['тип_1'] = d_df1.dtypes\n    temp_dict['имя признака_1'] = list_of_names1\n    temp_df1 = pd.DataFrame.from_dict(temp_dict)\n    \n    \n    list_of_names2 = list(d_df2.columns)\n    temp_dict2 = {}\n    temp_dict2['имя признака_2'] = list_of_names2\n    temp_dict2['тип_2'] = d_df2.dtypes\n    temp_dict2['в первой строке_2'] =d_df2.loc[0].values\n    temp_dict2['# уник_2'] = d_df2.nunique().values\n    temp_df2 = pd.DataFrame.from_dict(temp_dict2)\n    \n    temp_df = pd.concat([temp_df1,temp_df2], axis=1, sort=False)\n    temp_df.reset_index(inplace = True)\n    del temp_df['index']\n    display(temp_df)\n\n    temp_dict3 = {}\n    temp_df3= pd.DataFrame(temp_df)\n    temp_list  = []\n    temp_list2  = []\n    temp_list3  = []\n    temp_list4  = []\n    temp_list5  = []\n\n    for i in range(len(temp_df)):\n        if str(temp_df3['тип_2'][i]) != str(temp_df3['тип_1'][i]):\n            temp_list.append(temp_df3['имя признака_1'][i])\n            temp_list2.append(temp_df3['имя признака_2'][i])\n            temp_list3.append(str(temp_df3['тип_1'][i]) + '!=' + str(temp_df3['тип_2'][i]))\n            temp_list4.append(i)\n        if temp_df3['# уник_2'][i]>0 and temp_df3['# уник_1'][i]/temp_df3['# уник_2'][i] > 2:\n            temp_list5.append(i)\n            \n    temp_dict3['index']= temp_list4\n    temp_dict3['имя признака_1']= temp_list\n    temp_dict3['не совпадают типы'] = temp_list3\n    temp_dict3['имя признака_2']= temp_list2\n\n    temp_df4 = pd.DataFrame.from_dict(temp_dict3)\n    temp_df4.set_index('index',inplace=True)\n\n    print(f'Резюме:\\n 1. Не совпали типы в:= {len(temp_df4)} столбцах\\n')\n    print(f'2. Уникальные значения заоблачно различаются в:= {len(temp_list5)} столбцах {temp_list5}')\n    display(temp_df4)\n\n\n\n    return\n\n\ndef hbar_group_pivot_table(d_bodyType, \n                        d_group_col, \n                        d_df, \n                        d_year_start, \n                        d_year_end,\n                        d_my_font_scale):\n    temp_df = d_df.copy()\n    temp_df2 = temp_df[(temp_df['bodyType']==d_bodyType) & (temp_df['modelDate']>=d_year_start) & (temp_df['modelDate']<=d_year_end)]\n    \n\n    temp_pt_mean = pd.pivot_table(temp_df2, values =d_group_col, index =['bodyType','brand'], columns =['modelDate'],aggfunc = np.mean, margins=True)\n    temp_list = list(temp_pt_mean['All'][d_bodyType].index)\n\n    temp_pt_std = pd.pivot_table(temp_df2, values =d_group_col, index =['bodyType','brand'], columns =['modelDate'],aggfunc = np.std, margins=True)\n    temp_std = temp_pt_std['All'][d_bodyType]['BMW']\n    temp_mean = temp_pt_mean['All'][d_bodyType]['BMW']\n    a = temp_pt_mean['All'][d_bodyType]['BMW']-temp_std/2\n    b = temp_pt_mean['All'][d_bodyType]['BMW']+temp_std/2\n\n    temp_list2 = list(temp_pt_std['All'][d_bodyType].index)\n\n    temp_list_std =[]\n    list_overlapp_brands =[]\n    for brand in temp_list:\n        if brand in temp_list2:\n            std_ = temp_pt_std['All'][d_bodyType][brand]/2\n        else:\n            std_ = 0\n        temp_list_std.append(std_)\n        c = temp_pt_mean['All'][d_bodyType][brand] - std_\n        d = temp_pt_mean['All'][d_bodyType][brand] + std_\n        if brand != 'BMW' and ((b>=c and d>=a) or (a<=c and d<=b)):\n            list_overlapp_brands.append(brand)\n    \n    temp_std = temp_pt_std['All'][d_bodyType]['BMW']\n    temp_mean = temp_pt_mean['All'][d_bodyType]['BMW']\n\n    plt.style.use('seaborn-paper')\n    sns.set(font_scale=d_my_font_scale)\n    color_text = plt.get_cmap('PuBu')(0.85)\n    color_bar = plt.get_cmap('PuBu')(0.8)\n\n    plt.figure(figsize=(12, 6))\n    \n    plt.barh(temp_list, width=temp_pt_mean['All'][d_bodyType].values+temp_list_std, color =color_bar)\n    plt.barh(temp_list, width=temp_pt_mean['All'][d_bodyType].values, color ='red')\n    plt.barh(temp_list, width=temp_pt_mean['All'][d_bodyType].values-temp_list_std, color =color_bar)\n\n\n    plt.plot([temp_mean,temp_mean], [-1, len(temp_list)+1], color= 'red', label='среднее значение BMW', marker='.', lw=2, ls = '--')\n    plt.plot([temp_mean-temp_std/2,temp_mean-temp_std/2], [-1, len(temp_list)+1], color='grey', label='отклонение вниз на std/2', marker='.', lw=3)\n    plt.plot([temp_mean+temp_std/2,temp_mean+temp_std/2], [-1, len(temp_list)+1], color='blue', label='отклонение вверх на std/2', marker='.', lw=3)\n\n    plt.xlabel(d_group_col, fontsize=15, color = color_text)\n    plt.ylabel('brand', fontsize=15, color = color_text)\n    plt.title(f'Среднее и отклонение {d_group_col} сводной таблицы сгруппированной по {d_bodyType}. modelDate с {d_year_start} по {d_year_end}', color = color_text, fontsize=15)\n    plt.legend(loc=\"lower right\", fontsize=11)\n    # y_min_text = y_min +0.5*max(std_metric_train,std_metric_test)\n    plt.text(100, len(temp_list)-0.5, f'кол-во брендов авто попавших в сводную таблицу = {len(temp_list)} из 36 \\nкол-во брендов авто попадающих в область значений BMW = {len(list_overlapp_brands)} из 36', fontsize = 14)\n    plt.show()\n    print('Список релевантных брендов: ',*list_overlapp_brands)\n    return list_overlapp_brands\n\n\ndef vis_cross_val_score(d_name_metric, d_vec, d_value_metric, d_my_font_scale):\n    num_folds = len(d_vec['train_score'])\n    avg_metric_train, std_metric_train = d_vec['train_score'].mean(), d_vec['train_score'].std()\n    avg_metric_test, std_metric_test = d_vec['test_score'].mean(), d_vec['test_score'].std()\n\n    plt.style.use('seaborn-paper')\n    sns.set(font_scale=d_my_font_scale)\n    color_text = plt.get_cmap('PuBu')(0.85)\n\n    plt.figure(figsize=(12, 6))\n    plt.plot(d_vec['train_score'], label='тренировочные значения', marker='.', color= 'darkblue')\n    plt.plot([0,num_folds-1], [avg_metric_train, avg_metric_train], color='blue', label='среднее трен. значений ', marker='.', lw=2, ls = '--')\n\n    plt.plot(d_vec['test_score'], label='тестовые значения', marker='.', color= 'red')\n    plt.plot([0,num_folds-1], [avg_metric_test, avg_metric_test], color='lightcoral', label='среднее тест. значений ', marker='.', lw=2, ls = '--')\n\n    plt.plot([0,num_folds-1], [d_value_metric, d_value_metric], color='grey', label='значение метрики до CV', marker='.', lw=3)\n\n    # plt.xlim([1, num_folds])\n    y_max = max(avg_metric_train,avg_metric_test) + 1.5*max(std_metric_train,std_metric_test)\n    y_min = min(avg_metric_train,avg_metric_test) - 3*max(std_metric_train,std_metric_test)\n    plt.ylim([y_min, y_max])\n    plt.xlabel('номер фолда', fontsize=15, color = color_text)\n    plt.ylabel(d_name_metric, fontsize=15, color = color_text)\n    plt.title(f'Кросс-валидация по метрике {d_name_metric} на {num_folds} фолдах', color = color_text, fontsize=17)\n    plt.legend(loc=\"lower right\", fontsize=11)\n    y_min_text = y_min +0.5*max(std_metric_train,std_metric_test)\n    plt.text(0, y_min_text, f'{d_name_metric} на трейне = {round(avg_metric_train,3)} +/- {round(std_metric_train,3)} \\n{d_name_metric} на тесте    = {round(avg_metric_test,3)} +/- {round(std_metric_test,3)} \\n{d_name_metric} до CV        = {round(d_value_metric,3)}', fontsize = 15)\n    plt.show()\n    return\n\n\ndef model_coef(d_columns, d_model_coef_0):\n\n    temp_dict = {}\n    temp_dict['имя признака'] = d_columns\n    temp_dict['коэффициент модели'] = d_model_coef_0\n    temp_dict['модуль коэф'] = abs(temp_dict['коэффициент модели'])\n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='columns')\n    temp_df = temp_df.sort_values(by='модуль коэф', ascending=False)\n    temp_df.reset_index(drop=True,inplace=True)\n    \n    return temp_df.loc[:,['имя признака','коэффициент модели']]\n\ndef GridSearchCV_for_LogReg(d_X_train, d_y_train, d_values_for_C):\n    # Добавим типы регуляризации\n    penalty = ['l1', 'l2']\n\n    # Зададим ограничения для параметра регуляризации\n    C = np.array(d_values_for_C)\n\n    # Создадим гиперпараметры\n    hyperparameters = dict(C=C, penalty=penalty)\n\n    model = LogisticRegression(multi_class = 'ovr', class_weight='balanced')\n    model.fit(d_X_train, d_y_train)\n\n    # Создаем сетку поиска с использованием 5-кратной перекрестной проверки\n    clf = GridSearchCV(model, hyperparameters, cv=5, verbose=0, scoring='f1')\n\n    best_model = clf.fit(d_X_train, d_y_train)\n\n    # View best hyperparameters\n    temp_dict = {}\n    temp_dict['Penalty'] = [best_model.best_estimator_.get_params()['penalty']]\n    temp_dict['C'] = [best_model.best_estimator_.get_params()['C']]\n\n    # temp_dict['Признак'] = [best_model.best_index_]\n    # temp_list = sorted(clf.cv_results_.keys())\n    # temp_dict['Кол-во'] = [len(temp_list)]\n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index', columns=['Лучшие'])\n    display(temp_df)\n\n    temp_dict = {}\n    # temp_dict['Лучшие признаки'] = temp_list\n    # temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n    # display(temp_df.T)\n\n\n    return\n\n\n\ndef where_1_in_corr(d_df, d_y):\n\n    result = []\n    drop_list_columns = []\n    all_cols = list(d_df.columns)\n    for col in all_cols:\n        temp_list = d_df.index[d_df[col] == 1].tolist()\n        list1 = [x for x in temp_list if x not in [col]]\n        if list1 != []:\n            list1.append(col)\n            drop_list_columns.append(list1)\n    for i in range(len(drop_list_columns)//2):\n        result.append(drop_list_columns[i][0])\n    result= [x for x in result if x not in [d_y]]\n    return result\n\n\ndef PR_curve_with_area(d_y_true, d_y_pred_prob, d_my_font_scale):\n    \n\n    plt.style.use('seaborn-paper')\n    sns.set(font_scale=d_my_font_scale)\n    # sns.set_color_codes(\"muted\")\n\n    plt.figure(figsize=(8, 6))\n    precision, recall, thresholds = precision_recall_curve(d_y_true, d_y_pred_prob, pos_label=1)\n    prc_auc_score_f = auc(recall, precision)\n    plt.plot(precision, recall, lw=3, label='площадь под PR кривой = %0.3f)' % prc_auc_score_f)\n    \n    plt.xlim([-.05, 1.0])\n    plt.ylim([-.05, 1.05])\n    plt.xlabel('Точность \\n Precision = TP/(TP+FP)')\n    plt.ylabel('Полнота \\n Recall = TP/P')\n    plt.title('Precision-Recall кривая')\n    plt.legend(loc=\"upper right\")\n    plt.show()\n    return\n\n\ndef ROC_curve_with_area(d_y_true, d_y_pred_prob, d_my_font_scale):\n    roc_auc_score_f = roc_auc_score(d_y_true, d_y_pred_prob)\n\n    plt.style.use('seaborn-paper')\n    sns.set(font_scale=d_my_font_scale)\n    # sns.set_color_codes(\"muted\")\n\n    plt.figure(figsize=(8, 6))\n    fpr, tpr, thresholds = roc_curve(d_y_true, d_y_pred_prob, pos_label=1)\n\n    plt.plot(fpr, tpr, lw=3, label='площадь под ROC кривой = %0.3f)' % roc_auc_score_f)\n    plt.plot([0, 1], [0, 1], color='grey')\n    plt.xlim([-.05, 1.0])\n    plt.ylim([-.05, 1.05])\n    plt.xlabel('Ложно классифицированные \\n False Positive Rate (FPR)')\n    plt.ylabel('Верно классифицированные \\n True Positive Rate (TPR)')\n    plt.title('ROC кривая')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return\n\ndef test_last_pred(d_y_true, d_y_pred, d_y_pred_prob):\n    last_pred[0], last_pred[1], last_pred[2] = d_y_true, d_y_pred, d_y_pred_prob\n    return\n\n\n\ndef all_metrics_MAE_MPE_MAPE_WAPE_MSE_RMSE(d_y_true, d_y_pred):\n    def r_(d_x):\n        '''\n        short code for def round\n        '''\n        return round(d_x,6)\n\n\n    def r_p(d_x):\n        '''\n        short code for def round procent\n        '''\n        return round(d_x,4)\n\n\n    def MAE(y_true, y_pred):\n        '''\n        mean absolute error (средняя абсолютная ошибка)\n        '''\n        return np.mean(np.abs(y_true - y_pred))\n\n\n    def MPE(y_true, y_pred):\n        '''\n        mean percentage error (средняя процентная ошибка)\n        '''\n        return np.mean((y_true - y_pred) / y_true) * 100\n\n    \n    def MAPE(y_true, y_pred):\n        '''\n        mean absolute percentage error (средняя абсолютная процентная ошибка)\n        '''\n        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\n    \n    def SMAPE(y_true, y_pred):\n        '''\n        symmetric MAPE (симетричная средняя абсолютная процентная ошибка)\n        '''\n        return np.mean(2*np.abs(y_true - y_pred) / (np.abs(y_true)+np.abs(y_pred))) * 100\n    \n    def WMAPE(y_true, y_pred):\n        '''\n        weighted absolute percent error (взвешенная абсолютная процентная ошибка)\n        WMAPE / MAD-MEAN RATIO / WAPE — WEIGHTED ABSOLUTE PERCENT ERROR\n        '''\n        return np.mean(np.abs(y_true - y_pred)) / np.mean(y_true) * 100\n    \n\n    def RMSE(y_true, y_pred):\n        '''\n        root mean squared error (корень из среднеквадратичной ошибки)\n        '''\n        return mean_squared_error(y_true, y_pred)**0.5\n\n    \n    d_y_true_last, d_y_pred_last, d_y_pred_prob_last =  last_pred[0], last_pred[1], last_pred[2]\n    temp_dict = {}\n    temp1 = r_(MAE(d_y_true, d_y_pred))\n    temp2 = r_(MAE(d_y_true_last, d_y_pred_last))\n    temp_dict['MAE'] = [temp1, temp1-temp2,'mean absolute error (средняя абсолютная ошибка)']\n\n    temp1 = r_p(MPE(d_y_true, d_y_pred))\n    temp2 = r_p(MPE(d_y_true_last, d_y_pred_last))\n    temp_dict['MPE'] = [temp1, temp1-temp2,'(%) mean percentage error (средняя процентная ошибка)']\n    \n    temp1 = r_p(MAPE(d_y_true, d_y_pred))\n    temp2 = r_p(MAPE(d_y_true_last, d_y_pred_last))\n    temp_dict['MAPE'] = [temp1, temp1-temp2,'(%) mean absolute percentage error (средняя абсолютная процентная ошибка)']\n    \n    temp1 = r_p(SMAPE(d_y_true, d_y_pred))\n    temp2 = r_p(SMAPE(d_y_true_last, d_y_pred_last))\n    temp_dict['SMAPE'] = [temp1, temp1-temp2,'(%) symmetric MAPE (симетричная средняя абсолютная процентная ошибка)']    \n    \n    temp1 = r_p(WMAPE(d_y_true, d_y_pred))\n    temp2 = r_p(WMAPE(d_y_true_last, d_y_pred_last))\n    temp_dict['WMAPE'] = [temp1, temp1-temp2,'(%) weighted absolute percent error (взвешенная абсолютная процентная ошибка)']\n    \n    temp1 = r_(mean_squared_error(d_y_true, d_y_pred))\n    temp2 = r_(mean_squared_error(d_y_true_last, d_y_pred_last))\n    temp_dict['MSE'] = [temp1, temp1-temp2,'mean squared error (среднеквадратичная ошибка)']\n    \n    temp1 = r_(RMSE(d_y_true, d_y_pred))\n    temp2 = r_(RMSE(d_y_true_last, d_y_pred_last))\n    temp_dict['RMSE'] = [temp1, temp1-temp2,'root mean squared error (корень из среднеквадратичной ошибки)']    \n    \n    temp1 = r_(r2_score(d_y_true, d_y_pred))\n    temp2 = r_(r2_score(d_y_true_last, d_y_pred_last))\n    temp_dict['R2'] = [temp1, temp1-temp2,'coefficient of determination (коэффициент детерминации)']    \n    \n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index', columns=['Значение','Дельта с предыдущим','Описание'])\n    display(temp_df)\n\n    last_pred[0], last_pred[1] = d_y_true, d_y_pred\n\n    return\n\n\ndef all_metrics(d_y_true, d_y_pred, d_y_pred_prob):\n        \n    d_y_true_last, d_y_pred_last, d_y_pred_prob_last =  last_pred[0], last_pred[1], last_pred[2]\n    temp_dict = {}\n    temp1 = accuracy_score(d_y_true, d_y_pred)\n    temp2 = accuracy_score(d_y_true_last, d_y_pred_last)\n    temp_dict['accuracy'] = [temp1, temp2-temp1,'(TP+TN)/(P+N)']\n\n    temp1 = balanced_accuracy_score(d_y_true, d_y_pred)\n    temp2 = balanced_accuracy_score(d_y_true_last, d_y_pred_last)\n    temp_dict['balanced accuracy'] = [temp1, temp2-temp1,'сбалансированная accuracy']\n    \n    temp1 = precision_score(d_y_true, d_y_pred)\n    temp2 = precision_score(d_y_true_last, d_y_pred_last)\n    temp_dict['precision'] = [temp1, temp2-temp1,'точность = TP/(TP+FP)']\n    \n    temp1 = recall_score(d_y_true, d_y_pred)\n    temp2 = recall_score(d_y_true_last, d_y_pred_last)\n    temp_dict['recall'] = [temp1, temp2-temp1,'полнота = TP/P']\n    \n    temp1 = f1_score(d_y_true, d_y_pred)\n    temp2 = f1_score(d_y_true_last, d_y_pred_last)\n    temp_dict['f1_score'] = [temp1, temp2-temp1,'среднее гармоническое точности и полноты']\n    \n    temp1 = roc_auc_score(d_y_true, d_y_pred_prob)\n    temp2 = roc_auc_score(d_y_true_last, d_y_pred_prob_last)\n    temp_dict['roc_auc'] = [temp1, temp2-temp1,'Area Under Curve - Receiver Operating Characteristic']    \n    \n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index', columns=['Значение','Дельта с предыдущим','Описание'])\n    display(temp_df)\n\n    last_pred[0], last_pred[1], last_pred[2] = d_y_true, d_y_pred, d_y_pred_prob\n\n    return\n\ndef plot_confusion_matrix(y_true, y_pred, d_my_font_scale, classes,\n                          normalize=False,\n                          title=None):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    list_of_labels = [['TP','FP'],['FN','TN']]\n    \n    if not title:\n        if normalize:\n            title = 'Нормализованная матрица ошибок'\n        else:\n            title = 'Матрица ошибок без нормализации'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n\n    cm[0,0], cm[1,1] = cm[1,1], cm[0,0]\n\n    # # Only use the labels that appear in the data\n    # classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n   \n\n    plt.style.use('seaborn-paper')\n    cmap=plt.cm.Blues\n    color_text = plt.get_cmap('PuBu')(0.85)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.grid(False)\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           \n           title=title)\n    ax.title.set_fontsize(15)\n    ax.set_ylabel('Предсказанные значения', fontsize=14, color = color_text)\n    ax.set_xlabel('Целевая переменная', fontsize=14, color = color_text)\n    ax.set_xticklabels(classes, fontsize=12, color = 'black')\n    ax.set_yticklabels(classes, fontsize=12, color = 'black')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, list_of_labels[i][j]+'\\n'+format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\n\n\ndef confusion_matrix_f(d_name_columns, d_y, d_y_pred, d_my_font_scale, normalize=False):\n\n    class_names  = np.array(d_name_columns, dtype = 'U10')\n    # Plot non-normalized confusion matrix\n    plot_confusion_matrix(d_y, d_y_pred, d_my_font_scale, classes=class_names,\n                        title='Матрица ошибок без нормализации')\n\n    # Plot normalized confusion matrix\n    if normalize:\n        plot_confusion_matrix(d_y, d_y_pred, d_my_font_scale, classes=class_names, normalize=True,\n                        title='Нормализованная матрица ошибок')\n\n    plt.show()\n    return\n\n# функция для стандартизации\ndef StandardScaler_column(d_df, d_col):\n    scaler = StandardScaler()\n    scaler.fit(d_df[[d_col]])\n    return scaler.transform(d_df[[d_col]])\n\n\ndef StandardScaler_df_and_filna_0(d_df, d_columns):\n    # стандартизируем все столбцы кроме целевой и Sample\n    for i  in list(d_df[d_columns].columns):\n        d_df[i] = StandardScaler_column(d_df, i)\n        if len(d_df[d_df[i].isna()]) < len(d_df):\n            d_df[i] = d_df[i].fillna(d_df[i].min())\n    return\n\ndef get_dummies_df(d_df, d_columns):\n    star_list_columns = list(d_df.columns)\n    # реализуем метод OneHotLabels через get_dummies\n    d_df = pd.get_dummies(d_df, columns=d_columns, drop_first=True)\n    # мы специально не удаляем первоначальные столбы, чтобы потом можно было провести построчную проверку перед стандартизацией и моделированием \n    end_list_columns = list(d_df.columns)\n    new_dumm_cat_cols = [x for x in end_list_columns if x  not in star_list_columns]\n\n    temp_dict = {}\n    temp_dict['имя НОВОГО добавленного признака'] = new_dumm_cat_cols\n    temp_dict['тип признака'] = d_df[new_dumm_cat_cols].dtypes\n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n    display(temp_df.T)\n    return new_dumm_cat_cols\n\ndef scatterplot_with_hist(d_name_column_x, d_name_column_y, d_df):\n    temp_df = d_df\n    # Create Fig and gridspec\n    fig = plt.figure(figsize=(12, 8), dpi= 80)\n    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.2)\n\n    # Define the axes\n    ax_main = fig.add_subplot(grid[:-1, :-1])\n    ax_right = fig.add_subplot(grid[:-1, -1], xticklabels=[], yticklabels=[])\n    ax_bottom = fig.add_subplot(grid[-1, 0:-1], xticklabels=[], yticklabels=[])\n\n    # Scatterplot on main ax\n    ax_main.scatter(temp_df[d_name_column_x], temp_df[d_name_column_y], s=1, c=temp_df[d_name_column_y].astype('category').cat.codes)  #, , alpha=.9, data=df, cmap=\"tab10\", edgecolors='gray', linewidths=.5)\n\n    # histogram on the right\n    ax_bottom.hist(temp_df[d_name_column_x], 40, histtype='stepfilled', orientation='vertical', color='blue')\n    ax_bottom.invert_yaxis()\n\n    # histogram in the bottom\n    ax_right.hist(temp_df[d_name_column_y], 40, histtype='stepfilled', orientation='horizontal', color='blue')\n\n    # Decorations\n    ax_main.set(title='Scatterplot with Histograms \\n '+d_name_column_x+'vs'+ d_name_column_y, xlabel=d_name_column_x, ylabel=d_name_column_y)\n    ax_main.title.set_fontsize(20)\n    for item in ([ax_main.xaxis.label, ax_main.yaxis.label] + ax_main.get_xticklabels() + ax_main.get_yticklabels()):\n        item.set_fontsize(14)\n\n    xlabels = ax_main.get_xticks().tolist()\n    ax_main.set_xticklabels(xlabels)\n    plt.show()\n    return\n\n\ndef four_plot_with_log(d_name_plot,d_df):\n    \n    plt.style.use('seaborn-paper')\n    plt.rcParams['figure.figsize'] = (12, 3)\n\n    _, axs = plt.subplots(1, 4)\n    temp_df = d_df\n    axs[0].hist(temp_df,bins=11)\n    axs[0].set_title(d_name_plot)\n    axs[1].boxplot(temp_df)\n    axs[1].set_title('')\n    temp_df = d_df.apply(lambda x: math.log(x+1))\n    axs[2].hist(temp_df,bins=11)\n    axs[2].set_title('log')\n    axs[3].boxplot(temp_df)\n    axs[3].set_title('')\n    return\n\ndef four_plot_with_log2(d_name_column,d_df):\n    \n    plt.style.use('seaborn-paper')\n    plt.rcParams['figure.figsize'] = (12, 3)\n    color_text = plt.get_cmap('PuBu')(0.85)\n\n    \n    temp_df=d_df.copy()\n\n    fig = plt.figure()\n\n   \n    ax_1 = fig.add_subplot(1, 4, 1)\n    ax_2 = fig.add_subplot(1, 4, 2)\n    ax_3 = fig.add_subplot(1, 4, 3)\n    ax_4 = fig.add_subplot(1, 4, 4)\n\n    plt.suptitle(f'Гистограммы и box-plot для признака \\'{d_name_column}\\' и log({d_name_column})', fontsize=14, color = color_text, y=-0.02)\n\n    ax_1.hist(temp_df[d_name_column],bins=11)\n    ax_1.set_title(f'\\'{d_name_column}\\'', loc = 'right', fontsize=10, color = color_text)\n    ax_2.boxplot(temp_df[d_name_column])\n    \n    temp_name = 'log_'+d_name_column\n    temp_df.loc[:,temp_name] =  temp_df[d_name_column].apply(lambda x: math.log(x+1))\n\n    ax_3.hist(temp_df[temp_name],bins=11)\n    ax_3.set_title(f'log({d_name_column})', loc = 'right', fontsize=10, color = color_text)\n    ax_4.boxplot(temp_df[temp_name])\n    \n    plt.show()\n    return\n\n\ndef big_hist(d_name_column,d_df):\n    plt.style.use('seaborn-paper')\n    plt.rcParams['figure.figsize'] = (12, 3)\n\n    temp_df = d_df\n    temp_df[d_name_column].hist(bins=50)\n\n    return\n\n\ndef big_hist_log(d_name_column,d_df):\n    \n    plt.style.use('seaborn-paper')\n    plt.rcParams['figure.figsize'] = (12, 3)\n\n    temp_df = d_df.copy()\n    temp_df['log_'+d_name_column] = temp_df[d_name_column].apply(lambda x: math.log(x+1))\n\n    temp_df['log_'+d_name_column].hist(bins=50)\n\n    return\n\n\ndef borders_of_outliers(d_name_column,d_df, log = False):\n    \n    if log:\n        temp_df = d_df[d_name_column].apply(lambda x: math.log(x+1))\n    else:\n        temp_df = d_df[d_name_column]\n    IQR = temp_df.quantile(0.75) - temp_df.quantile(0.25)\n    perc25 = temp_df.quantile(0.25)\n    perc75 = temp_df.quantile(0.75)\n    left_border = perc25 - 1.5*IQR\n    right_border = perc75 + 1.5*IQR\n\n    temp_dict = {}\n    if log:\n        temp_dict['границы выбросов с логарифмом'] = [left_border, right_border]\n        temp_dict['границы выбросов без логарифма'] = [math.exp(left_border)-1, math.exp(right_border)-1]\n        count_values_left = (temp_df<left_border).sum()\n        count_values_right = (temp_df>right_border).sum()\n        temp_dict['кол-во значений за границей'] = [count_values_left, count_values_right]\n\n    else:\n        temp_dict['границы выбросов'] = [left_border, right_border]\n        count_values_left = (temp_df<left_border).sum()\n        count_values_right = (temp_df>right_border).sum()\n        temp_dict['кол-во значений за границей'] = [count_values_left, count_values_right]\n        \n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index', columns=['левая','правая'])\n    display(temp_df)\n    return \n\n\ndef describe_with_hist(d_name_plot,d_df):\n    temp_describe = d_df.describe()\n    temp_dict = {}\n    temp_dict['кол-во строк'] = len(d_df)\n    temp_dict['тип значений'] = d_df.dtype\n    temp_dict['кол-во значений'] = temp_describe[0]\n    temp_dict['кол-во NaN'] = (d_df.isna()).sum()\n    temp_dict['среднее'] = temp_describe[1]\n    temp_dict['медиана'] = temp_describe[5]\n    temp_dict['мин'] = temp_describe[3]\n    temp_dict['макс'] = temp_describe[7]\n\n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index', columns=[d_name_plot])\n    display(temp_df)\n\n    plt.style.use('seaborn-paper')\n    plt.rcParams['figure.figsize'] = (4, 3)\n    color_text = plt.get_cmap('PuBu')(0.85)\n    \n    plt.title(f'Гистограмма признака \\'{d_name_plot}\\' ', fontsize=12, color = color_text)\n    n_bins = d_df.nunique()\n    if n_bins >15:\n        n_bins = 15\n    d_df.hist(bins=n_bins)\n    return\n\n\ndef describe_without_plots(d_name_plot,d_df):\n    temp_describe = d_df.describe().copy()\n    temp_dict = {}\n    temp_dict['кол-во строк'] = len(d_df)\n    temp_dict['тип значений'] = d_df.dtype\n    temp_dict['кол-во значений'] = temp_describe[0]\n    temp_dict['кол-во NaN'] = (d_df.isna()).sum()\n    temp_dict['среднее'] = temp_describe[1]\n    temp_dict['медиана'] = temp_describe[5]\n    temp_dict['мин'] = temp_describe[3]\n    temp_dict['макс'] = temp_describe[7]\n\n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index', columns=[d_name_plot])\n    display(temp_df)\n\n    return\n\n\ndef describe_without_plots_all_collumns(d_df, full=True, short=False):\n    list_of_names = list(d_df.columns)\n    temp_dict = {}\n    temp_dict['имя признака'] = list_of_names\n    temp_dict['тип'] = d_df.dtypes\n    temp_dict['# значений'] = d_df.describe(include='all').loc['count']\n    temp_dict['# пропусков(NaN)'] = d_df.isnull().sum().values \n    temp_dict['# уникальных'] = d_df.nunique().values\n    if not short:\n        temp_dict['в первой строке'] =d_df.loc[0].values\n        temp_dict['во второй строке'] = d_df.loc[1].values\n        temp_dict['в третьей строке'] = d_df.loc[2].values\n    if full :\n        temp_dict['минимум'] = d_df.describe(include='all').loc['min']\n        temp_dict['среднее'] = d_df.describe(include='all').loc['mean']\n        temp_dict['макс'] = d_df.describe(include='all').loc['max']\n        temp_dict['медиана'] = d_df.describe(include='all').loc['50%']\n    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n    display(temp_df.T)\n\n    return\n\n\n\ndef classic_round(d_num):\n    return int(d_num + (0.5 if d_num > 0 else -0.5))\n\n\ndef my_round(d_pred):\n    result = classic_round(d_pred*2)/2\n    if result <=5:\n        return result\n    else:\n        return 5\n\n\ndef test_model(d_df,d_list_remove_columns, d_RS):\n    train_data = d_df.query('Sample == 1').drop(['Sample']+d_list_remove_columns, axis=1, errors='ignore')\n    test_data = d_df.query('Sample == 0').drop(['Sample']+d_list_remove_columns, axis=1, errors='ignore')\n\n    y = train_data.Rating.values\n    X = train_data.drop(['Rating'], axis=1)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=d_RS)\n    print(test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape)\n    model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=d_RS)\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n\n    my_vec_round = np.vectorize(my_round)\n    y_pred = my_vec_round(y_pred)\n    temp_MAE = metrics.mean_absolute_error(y_test, y_pred)\n\n    print(temp_MAE)\n    return\n\n\ndef simple_plot_barh_procent(d_name_title, d_category_names, d_name_column, d_df):\n    \"\"\"\n    \n    \"\"\"\n    list_values = list(d_df[d_name_column].unique())\n    if len(d_category_names) != len(list_values):\n        return print('Кол-во категорий не совпадает с кол-вом значений')\n    else:\n        temp_df = d_df[d_name_column].value_counts(normalize=True)*100\n\n        plt.style.use('seaborn-paper')\n        _, ax = plt.subplots(figsize=(10, 2))\n        \n        category_colors = plt.get_cmap('PuBu')(\n                np.linspace(0.85, 0.35, len(list_values)))\n\n        widths = temp_df.values\n        starts = temp_df.cumsum() - widths\n        ax.barh(0, width = widths, left=starts, height=0.3, color=category_colors)\n        xcenters = starts + widths / 2\n        text_color = 'white'\n        for (x, w, c_n, k) in zip(xcenters, widths, d_category_names, temp_df.keys()):\n            ax.text(x,-0.05, str(int(w))+'%', fontsize=18, weight = 'bold', ha='center', va='center',\n                    color=text_color)\n            ax.text(x,0.05, c_n +'  ('+str(k)+')', fontsize=14, weight = 'bold', ha='center', va='center',\n                    color=text_color)\n        ax.set_title(d_name_title+' (критерий '+d_name_column+')', loc ='center', fontsize=12, color = category_colors[0])\n\n        plt.show()\n    return\n\n\ndef simple_balalayka(d_category_names, \n                     d_name_column_base_x, \n                     d_name_column_group_y, \n                     d_df, \n                     d_my_font_scale):\n    \"\"\"\n    \n    \"\"\"\n    list_values = list(d_df[d_name_column_base_x].unique())\n    if len(d_category_names) != len(list_values):\n        return print('Кол-во категорий не совпадает с кол-вом значений')\n    else:\n        plt.style.use('seaborn-paper')\n        plt.subplots(figsize=(12, 4))\n        color_text = plt.get_cmap('PuBu')(0.85)\n\n        sns.set(font_scale=d_my_font_scale, style='whitegrid')\n        plt.subplot(111)\n        b = sns.swarmplot(x=d_name_column_base_x, y=d_name_column_group_y, data=d_df, label= d_name_column_base_x[0], palette=\"PuBu\")\n        b.set_title(f'Распределение {d_name_column_base_x} and {d_name_column_group_y}', \n                        fontsize=12, color = color_text)\n        b.set_ylabel(d_name_column_group_y, fontsize=14, color = color_text)\n        b.set_xlabel(d_name_column_base_x, fontsize=14, color = color_text)\n\n        b.legend(labels=d_category_names, ncol=2, fancybox=True, framealpha=0.75, shadow=True, bbox_to_anchor=(0.5, -0.3), loc='center')\n    return\n\n\ndef simple_boxplot(d_category_names, \n                     d_name_column_base_x, \n                     d_name_column_group_y, \n                     d_df, \n                     d_my_font_scale,\n                     log = False):\n    \"\"\"\n    \n    \"\"\"\n    \n    list_values = list(d_df[d_name_column_base_x].unique())\n    if len(d_category_names) != len(list_values):\n        return print('Кол-во категорий не совпадает с кол-вом значений')\n    else:\n        temp_df = d_df\n        if log:\n            \n            temp_df[d_name_column_group_y] = temp_df[d_name_column_group_y].apply(lambda x: math.log(x+1))\n        \n        plt.style.use('seaborn-paper')\n        plt.subplots(figsize=(6, 4))\n        color_text = plt.get_cmap('PuBu')(0.85)\n\n        sns.set(font_scale=d_my_font_scale, style='whitegrid')\n        plt.subplot(111)\n        b = sns.boxplot(x=d_name_column_base_x, y=d_name_column_group_y, data=temp_df, palette=\"PuBu\")\n        b.set_title(f'boxplot распределения значений {d_name_column_base_x} по {d_name_column_group_y}', \n                        fontsize=12, color = color_text)\n        b.set_ylabel(d_name_column_group_y, fontsize=14, color = color_text)\n        b.set_xlabel(d_name_column_base_x, fontsize=14, color = color_text)\n\n        b.legend(labels=d_category_names, ncol=2, fancybox=True, framealpha=0.75, shadow=True, bbox_to_anchor=(0.5, -0.3), loc='center')\n    return\n\n\ndef plot_filter_df_kde(d_category_names, \n                       d_name_column_filter, \n                       d_name_column_group_x, \n                       d_df,\n                       d_my_font_scale):\n    \"\"\"\n    \n    \"\"\"\n    list_values = list(d_df[d_name_column_filter].unique())\n    list_values = sorted(list_values)\n\n    if len(d_category_names) != len(list_values):\n        return print('Кол-во категорий не совпадает с кол-вом значений')\n    else:\n        for i in range(len(d_category_names)):\n            d_category_names[i] = d_category_names[i] + ' ('+str(list_values[i])+')'\n        plt.style.use('seaborn-paper')\n        plt.subplots(figsize=(6, 4))\n\n        category_colors = plt.get_cmap('PuBu')(np.linspace(0.85, 0.35, len(list_values)))\n        color_text = plt.get_cmap('PuBu')(0.85)\n\n        sns.set(font_scale=d_my_font_scale, style='whitegrid')\n        plt.subplot(111)\n        for x,i in zip(list_values, range(len(list_values))):\n            temp_df = d_df.loc[d_df[d_name_column_filter] == x, d_name_column_group_x]\n            k=sns.kdeplot(temp_df, color=category_colors[i], label=x)\n\n        k.set_title(f'Плотность распределений {d_name_column_group_x} с фильтрами по  {d_name_column_filter}', \n                        fontsize=12, color = color_text)\n        k.set_xlabel(d_name_column_group_x, fontsize=14, color = color_text)\n\n        k.legend(labels=d_category_names, ncol=len(list_values), fancybox=True, framealpha=0.75, shadow=True, bbox_to_anchor=(0.5, -0.3), loc='center')\n    return\n\n\ndef group_plot_hbar_count(d_category_names, \n                         d_name_column_base_x, \n                         d_name_column_group_y, \n                         d_df,\n                         d_my_font_scale):\n    \"\"\"\n    \n    \"\"\"\n    list_values = list(d_df[d_name_column_base_x].unique())\n    if len(d_category_names) != len(list_values):\n        return print('Кол-во категорий не совпадает с кол-вом значений')\n    else:\n        temp_df = d_df.copy()\n        plt.style.use('seaborn-paper')\n        plt.subplots(figsize=(6, 4))\n        color_text = plt.get_cmap('PuBu')(0.85)\n        sns.set(font_scale=d_my_font_scale, style='whitegrid')\n\n        plt.subplot(111)\n        b = sns.barplot(y=d_name_column_base_x, \n                        x=d_name_column_group_y, \n                        data=temp_df, \n                        palette=\"PuBu\", \n                        ci=None, \n                        orient ='h',\n                        hue=d_name_column_base_x)\n\n        b.set_title(f'vplot распределения сред. знач. {d_name_column_group_y} сгруп-ные по {d_name_column_base_x}', \n                    fontsize=12, color = color_text)\n        b.set_ylabel(d_name_column_group_y, fontsize=14, color = color_text)\n        b.set_xlabel(d_name_column_base_x, fontsize=14, color = color_text)\n\n        b.legend(labels=d_category_names, ncol=2, fancybox=True, framealpha=0.75, shadow=True, bbox_to_anchor=(0.5, -0.3), loc='center')\n        \n    return\n\ndef group_plot_barv_mean(d_category_names, \n                         d_name_column_base_x, \n                         d_name_column_group_y, \n                         d_df,\n                         d_my_font_scale):\n    \"\"\"\n    \n    \"\"\"\n    list_values = list(d_df[d_name_column_base_x].unique())\n    if len(d_category_names) != len(list_values):\n        return print('Кол-во категорий не совпадает с кол-вом значений')\n    else:\n        temp_df = d_df.copy()\n        plt.style.use('seaborn-paper')\n        plt.subplots(figsize=(6, 4))\n        color_text = plt.get_cmap('PuBu')(0.85)\n        sns.set(font_scale=d_my_font_scale, style='whitegrid')\n\n        plt.subplot(111)\n        b = sns.barplot(x=d_name_column_base_x, y=d_name_column_group_y, data=temp_df, palette=\"PuBu\", ci=None, hue=d_name_column_base_x)\n\n        b.set_title(f'vplot распределения сред. знач. {d_name_column_group_y} сгруп-ные по {d_name_column_base_x}', \n                    fontsize=12, color = color_text)\n        b.set_ylabel(d_name_column_group_y, fontsize=14, color = color_text)\n        b.set_xlabel(d_name_column_base_x, fontsize=14, color = color_text)\n\n        b.legend(labels=d_category_names, ncol=2, fancybox=True, framealpha=0.75, shadow=True, bbox_to_anchor=(0.5, -0.3), loc='center')\n        \n    return\n\n\n\ndef simple_heatmap(d_title, d_df, d_list_of_columns, d_my_font_scale, d_g, d_size):\n    \"\"\"\n    \n    \"\"\"\n    temp_df = d_df[d_list_of_columns].copy()\n\n    plt.style.use('seaborn-paper')\n    plt.subplots(figsize=(d_size, 6))\n    color_text = plt.get_cmap('PuBu')(0.85)\n    sns.set(font_scale=d_my_font_scale, style='whitegrid')\n\n    plt.subplot(111)\n    h = sns.heatmap(temp_df.corr(), annot = True, fmt=f'.{d_g}g', cmap= \"PuBu\", center= 0)\n    h.set_title(d_title,  fontsize=14, color = color_text)\n\n    return\n\ndef binned(df, col_name, bins_no=11):\n    # df - имя датафрейма, col_name - наименование признака, который надо разбить на интервалы, \n    # bins - количество интервалов разбиения\n    # пример: data['age_binned'] = binned(data,'age',18)\n\n    if not pd.api.types.is_numeric_dtype(df[col_name]):\n        print(f'Признак {col_name} не численный, разбиение невозможно')\n        return\n    else:\n        # Вычисляем минимум и максимум разбиения\n        bottom = df[col_name].min()\n        top = df[col_name].max()\n        # Возвращаем признак, разбитый на интервалы\n        return pd.cut(df[col_name], bins = np.linspace(bottom, top, num = bins_no))\n\ndef StandardScaler_FillNa_0(d_df):\n    return\n\n\n\n\nif __name__ == \"__main__\":\n    print('What do you do?')","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}